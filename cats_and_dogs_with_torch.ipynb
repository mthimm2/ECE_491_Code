{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import perf_counter\n",
    "import pandas as pd\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The flag below controls whether to allow TF32 on matmul. This flag defaults to True.\n",
    "# torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "# torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# Another performance enhancing flag?\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory path of our entire image set\n",
    "# IMAGES_LOCATION = os.path.join(os.getcwd(), 'all')\n",
    "# \n",
    "# with open('labels_file.csv', 'w') as outfile:\n",
    "    # for file in os.listdir(IMAGES_LOCATION):\n",
    "        # if 'cat' in file:\n",
    "            # outfile.write(f'{file}, 0')\n",
    "        # elif 'dog' in file:\n",
    "            # outfile.write(f'{file}, 1')\n",
    "        # outfile.write('\\n')\n",
    "    # outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Path of our csv file\n",
    "LABELS_LOCATION = 'labels_file.csv'\n",
    "\n",
    "# The directory path of our entire image set\n",
    "IMAGES_LOCATION = os.path.join(os.getcwd(), 'all')\n",
    "\n",
    "# Custom dataset example for the cats and dogs\n",
    "class CatsAndDogsDataset(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, csv_file, root_dir, transform = None):\n",
    "\n",
    "        # This CSV file will contain the image names in one column and the labels in the other\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Return image at row i, hence iloc, column 0, which is the image name\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "\n",
    "        image = io.imread(img_path)\n",
    "\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, y_label)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Image constants and batch size\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# Declare our transforms ahead of time\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
    "    transforms.Grayscale()    \n",
    "])\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = CatsAndDogsDataset(csv_file = LABELS_LOCATION, root_dir = IMAGES_LOCATION, transform = transform)\n",
    "\n",
    "print(len(dataset))\n",
    "\n",
    "# Split data into train and test\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [20000, 4999])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(test_set, batch_size = BATCH_SIZE, shuffle = True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datapath of the training data\n",
    "TRAIN_DIR = os.path.join(os.getcwd(), 'train')\n",
    "TEST_DIR = os.path.join(os.getcwd(), 'test')\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# The preprocessing that we'll perform to each image\n",
    "# If we want to do multiple transforms, it looks like we have to do it in this way.\n",
    "preprocessing = transforms.Compose([\n",
    "    \n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
    "    transforms.ToTensor()\n",
    "    \n",
    "\n",
    "])\n",
    "\n",
    "# This will take images from a given root directory and assign labels based on subdirectory structure.\n",
    "# The transform argument does not look like it can accept a list of transforms, based on experimentation\n",
    "train_set_setup = datasets.ImageFolder(\n",
    "    TRAIN_DIR, transform = preprocessing\n",
    ")\n",
    "\n",
    "test_set_setup = datasets.ImageFolder(\n",
    "    TEST_DIR, transform = preprocessing\n",
    ")\n",
    "\n",
    "# Load in the data, batch, and shuffle\n",
    "train_set = DataLoader(train_set_setup, batch_size = BATCH_SIZE, shuffle = True, pin_memory = True, num_workers = 8, prefetch_factor=1)\n",
    "test_set = DataLoader(test_set_setup, batch_size = BATCH_SIZE, shuffle = True, pin_memory = True, num_workers = 8, prefetch_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The neural network itself is a subclass of nn.Module\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "\n",
    "        # Acknowledgement of derivation from nn.Module\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        # self.linear_relu_stack = nn.Sequential(\n",
    "        #     nn.Linear(IMAGE_HEIGHT * IMAGE_WIDTH, 256),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(256, 1024),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(1024, 10),\n",
    "        # )\n",
    "        \n",
    "        self.conv_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size = 2, stride = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size = 5, stride = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 64, kernel_size = 2, stride = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 16, kernel_size = 4, stride = 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    # How the data is actually fed through the network\n",
    "    def forward(self, x):\n",
    "        #logits = self.linear_relu_stack(x)\n",
    "        logits = self.conv_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before building the network, we need to check if the GPU is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our network and send it to the GPU\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare our hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = BATCH_SIZE\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify our loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training process in Pytorch isn't fully automated as in Tensorflow\n",
    "def train_loop(train_set, model, loss_fn, optimizer):\n",
    "\n",
    "    # Size of the dataset\n",
    "    size = len(train_set.dataset)\n",
    "\n",
    "    start = perf_counter()\n",
    "\n",
    "    # Go over each item in each batch of the training set\n",
    "    for batch, (x, y) in enumerate(train_set):\n",
    "\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "\n",
    "        # Make a prediction, then calculate the loss\n",
    "        # The x.cuda() syntax denotes the fact that we're sending the batch to the GPU\n",
    "        prediction = model(x)\n",
    "        loss = loss_fn(prediction, y)\n",
    "\n",
    "        # Resets the gradient so that we don't use an old one\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate the gradient based on the calculated loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Optional prinouts for progress\n",
    "        if batch == len(train_set) - 1:\n",
    "\n",
    "            end = perf_counter()\n",
    "\n",
    "            # Get data about every 10th epoch\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "\n",
    "            # loss and batch out of total?\n",
    "            print(f'Loss: {loss:>7f} [{current:>5d}/{size:>5d}] | Time per epoch = {end - start:>3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test loop is somewhat similar, but does not use gradient descent\n",
    "def test_loop(test_set, model, loss_fn):\n",
    "\n",
    "    size = len(test_set.dataset)\n",
    "\n",
    "    num_batches = len(test_set)\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # The inference part. No weight updates, etc.\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for x,y in test_set:\n",
    "\n",
    "            # We have to send each batch to the GPU\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            pred = model(x)\n",
    "\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "# print(pytorch_total_params)\n",
    "for x in range(epochs):\n",
    "    train_loop(train_set, model, loss_fn, optimizer)\n",
    "\n",
    "test_loop(test_set, model, loss_fn)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a77a30e21dbfcb5c6946afd89539d692c734ea53162231afa6d1511e7906bc2c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
